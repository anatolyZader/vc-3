# File Identity Preservation - Complete Flow Analysis

## ğŸ¯ Question: How is File Identity Preserved from Chunking to Retrieval?

**Answer**: File identity is preserved through the `metadata.source` field that flows through every stage of the pipeline, from document loading through chunking, storage, and retrieval.

---

## ğŸ“Š Complete Identity Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: DOCUMENT LOADING (Identity Created)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    CloudNativeRepoLoader.load() OR GithubRepoLoader.load()
                    â†“
    Creates LangChain Document with metadata.source:
    {
      pageContent: "file contents...",
      metadata: {
        source: "backend/business_modules/ai/infrastructure/search/textSearchService.js",
        type: "github-code",
        repository: "anatolyZader/vc-3",
        branch: "main",
        sha: "abc123...",
        loaded_at: "2025-10-30T...",
        ... other metadata
      }
    }
    
    KEY FIELD: metadata.source = full file path
    âœ… Identity established at origin

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: DOCUMENT PROCESSING (Identity Preserved)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    repoProcessor.intelligentProcessDocuments(documents)
                    â†“
    Processes each document but PRESERVES metadata.source:
    
    Each processor (codePreprocessor, textPreprocessor) receives:
    - Input: document with metadata.source
    - Output: processed document with SAME metadata.source
    
    âœ… Identity carried through processing

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: DOCUMENT SPLITTING (Identity Inherited by Chunks)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    routeDocumentsToProcessors() â†’ processCodeDocument()
                    â†“
    1. astCodeSplitter.split() creates multiple chunks from one file
    2. Each chunk inherits parent metadata INCLUDING source:
    
    rawChunks.map(chunk => ({
      pageContent: chunk.pageContent,
      metadata: {
        ...ubiquitousEnhanced.metadata,  // â† Includes source!
        ...chunk.metadata,               // â† Chunk-specific data
        chunkIndex: 0                    // â† Which chunk of the file
      }
    }))
    
    Result: Each chunk knows its source file:
    {
      pageContent: "function handleRequest() { ... }",
      metadata: {
        source: "backend/.../textSearchService.js",  â† PRESERVED
        chunkIndex: 2,                               â† 3rd chunk of file
        chunkTokens: 250,
        function_names: ["handleRequest"],
        ... all other metadata
      }
    }
    
    âœ… Identity replicated to all chunks from same file

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: SEMANTIC ENHANCEMENT (Identity Still Preserved)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    semanticPreprocessor.preprocessChunk(chunk)
                    â†“
    Adds semantic metadata but KEEPS source intact:
    
    return {
      pageContent: chunk.pageContent,
      metadata: {
        ...chunk.metadata,              // â† Includes source!
        semantic_role: "controller",
        layer: "infrastructure",
        semantic_tags: ["api", "handler"],
        ... new semantic fields
      }
    }
    
    âœ… Identity preserved through enhancement

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5A: PINECONE STORAGE (Identity in Metadata)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    embeddingManager.storeToPinecone(splitDocuments, ...)
                    â†“
    pineconeService.upsertDocuments(documents, embeddings, options)
                    â†“
    For each chunk:
    {
      id: "generated-unique-id",
      values: [0.123, 0.456, ...],  // Embedding vector
      metadata: {
        source: "backend/.../textSearchService.js",  â† STORED
        text: chunk.pageContent,
        chunkIndex: 2,
        semantic_role: "controller",
        ... ALL metadata stored
      }
    }
    
    Pinecone stores:
    - Vector embedding (for similarity search)
    - FULL metadata object including source
    
    âœ… Identity stored in Pinecone metadata

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5B: POSTGRESQL STORAGE (Identity in Column + Metadata)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    textSearchService.storeChunks(splitDocuments, userId, repoId)
                    â†“
    aiPostgresAdapter.storeRepoChunks(chunks, userId, repoId)
                    â†“
    For each chunk:
    
    const filePath = chunk.metadata?.source || 'unknown';
    
    INSERT INTO repo_data (
      user_id, 
      repo_id, 
      file_path,                    â† DEDICATED COLUMN for source
      file_extension,
      chunk_index,
      chunk_content,
      chunk_tokens,
      metadata,                      â† JSON with ALL metadata
      language
    ) VALUES (
      userId,
      repoId,
      'backend/.../textSearchService.js',  â† Extracted from metadata.source
      'js',
      2,
      chunk.pageContent,
      250,
      JSON.stringify({
        source: 'backend/.../textSearchService.js',  â† ALSO in JSON
        semantic_tags: [...],
        ubiquitous_language: [...],
        ... all metadata
      }),
      'english'
    )
    
    PostgreSQL stores TWICE:
    1. file_path column (for fast filtering/searching)
    2. metadata JSON (for complete context)
    
    UNIQUE CONSTRAINT: (user_id, repo_id, file_path, chunk_index)
    â†’ Ensures no duplicate chunks from same file
    
    âœ… Identity stored in both column and metadata

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 6: RETRIEVAL - PINECONE (Identity Returned)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User Query: "explain how textSearchService works"
                    â†“
    vectorSearchOrchestrator.performSearch(prompt)
                    â†“
    1. Generate query embedding: embeddings.embedQuery(prompt)
    2. Query Pinecone: pineconeService.querySimilar(embedding, options)
                    â†“
    Pinecone returns matches with FULL metadata:
    {
      matches: [
        {
          id: "chunk-id-123",
          score: 0.87,
          metadata: {
            source: "backend/.../textSearchService.js",  â† RETURNED
            text: "class TextSearchService { ... }",
            chunkIndex: 0,
            semantic_role: "controller",
            function_names: ["searchDocuments", "storeChunks"],
            ... all stored metadata
          }
        },
        {
          id: "chunk-id-124",
          score: 0.85,
          metadata: {
            source: "backend/.../textSearchService.js",  â† RETURNED
            text: "async searchDocuments(query) { ... }",
            chunkIndex: 1,
            ... metadata
          }
        }
      ]
    }
    
    âœ… Source file path returned with each match

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 7: RETRIEVAL - POSTGRESQL (Identity Returned)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User Query: "textSearchService"
                    â†“
    textSearchService.searchDocuments(searchQuery, options)
                    â†“
    Query detects filename and searches:
    
    SELECT 
      id,
      user_id,
      repo_id,
      file_path,              â† Source file path in column
      file_extension,
      chunk_index,
      chunk_content,
      chunk_tokens,
      metadata,               â† JSON with complete metadata
      ... relevance ranking
    FROM repo_data
    WHERE file_path ILIKE '%textSearchService%'
    ORDER BY rank DESC, file_path ASC, chunk_index ASC
                    â†“
    Returns:
    {
      filePath: "backend/.../textSearchService.js",  â† From column
      chunkIndex: 0,
      content: "class TextSearchService { ... }",
      metadata: {
        source: "backend/.../textSearchService.js",  â† From JSON
        semantic_tags: [...],
        ubiquitous_language: [...],
        ... all metadata
      }
    }
    
    âœ… Source file path returned from both column and JSON

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 8: CONTEXT BUILDING (Identity Used for Citations)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    queryPipeline.answerQuery(prompt)
                    â†“
    contextBuilder.formatSearchResults(results)
                    â†“
    For each result:
    
    const source = doc.metadata.source || 'Unknown source';
    
    Formatted output:
    ```
    ## Context from: backend/business_modules/ai/infrastructure/search/textSearchService.js
    
    ```javascript
    class TextSearchService {
      async searchDocuments(searchQuery, options = {}) {
        // ... code ...
      }
    }
    ```
    
    Sources:
    - backend/business_modules/ai/infrastructure/search/textSearchService.js
    - backend/business_modules/ai/infrastructure/persistence/aiPostgresAdapter.js
    ```
    
    âœ… User sees exact file paths in response

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 9: CHUNK RECONSTRUCTION (Identity for Grouping)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    When multiple chunks from same file are retrieved:
    
    Results = [
      { metadata: { source: "textSearchService.js", chunkIndex: 0 } },
      { metadata: { source: "textSearchService.js", chunkIndex: 1 } },
      { metadata: { source: "textSearchService.js", chunkIndex: 2 } },
      { metadata: { source: "aiPostgresAdapter.js", chunkIndex: 0 } }
    ]
                    â†“
    Can be grouped by source for presentation:
    
    File: textSearchService.js
      - Chunk 0: class definition
      - Chunk 1: searchDocuments method
      - Chunk 2: storeChunks method
    
    File: aiPostgresAdapter.js
      - Chunk 0: storeRepoChunks method
    
    âœ… Chunks can be reunited by source file
```

---

## ğŸ” Identity Preservation Mechanisms

### 1. **Initial Assignment (Loading Stage)**

**Location**: `cloudNativeRepoLoader.js:242-250` or `GithubRepoLoader`

```javascript
// Create LangChain-compatible document
const document = {
  pageContent: content,
  metadata: {
    source: fileInfo.path,  // â† CRITICAL: Full path from GitHub
    type: fileType,
    size: data.size,
    sha: data.sha,
    repository: `${this.owner}/${this.repo}`,
    branch: this.branch,
    loaded_at: new Date().toISOString(),
    loading_method: 'cloud_native_api'
  }
};
```

**Key**: `metadata.source` = full file path from GitHub tree

### 2. **Metadata Inheritance (Chunking Stage)**

**Location**: `contextPipeline.js:256-263`

```javascript
const chunks = rawChunks.map(chunk => ({
  pageContent: chunk.pageContent,
  metadata: {
    ...ubiquitousEnhanced.metadata,  // â† Parent metadata (includes source)
    ...chunk.metadata                 // â† Chunk-specific metadata
  }
}));
```

**Key**: Child chunks inherit `source` from parent document

### 3. **Explicit Extraction (PostgreSQL Storage)**

**Location**: `aiPostgresAdapter.js:253`

```javascript
const filePath = chunk.metadata?.source || chunk.metadata?.filePath || 'unknown';
```

**Key**: Explicitly extracts source for database column

### 4. **Metadata Passthrough (Pinecone Storage)**

**Location**: `pineconeService.js:123-169`

```javascript
const vectors = documents.map((doc, index) => ({
  id: ids[index],
  values: embeddings[index],
  metadata: {
    text: doc.pageContent,
    ...doc.metadata  // â† ALL metadata including source
  }
}));
```

**Key**: All metadata (including source) stored with vector

### 5. **Return in Results (Retrieval)**

**Location**: `vectorSearchOrchestrator.js:133-139`

```javascript
convertToLegacyFormat(matches) {
  return matches.map(match => ({
    pageContent: match.metadata?.text || '',
    metadata: {
      ...match.metadata,  // â† Includes source
      score: match.score,
      id: match.id
    }
  }));
}
```

**Key**: Metadata (with source) returned in results

### 6. **Citation in Response (Context Building)**

**Location**: `queryPipeline.js:940`

```javascript
- **Source**: ${doc.metadata.source || 'Unknown'}
```

**Key**: Source displayed to user in formatted response

---

## ğŸ¯ Critical Identity Fields

### Primary Identity Field

```javascript
metadata.source: "backend/business_modules/ai/infrastructure/search/textSearchService.js"
```

**Always present in**:
- âœ… Raw documents (from loader)
- âœ… Processed documents
- âœ… Split chunks
- âœ… Enhanced chunks
- âœ… Pinecone vectors
- âœ… PostgreSQL rows (as `file_path` column AND in `metadata` JSON)
- âœ… Search results
- âœ… Context for LLM
- âœ… Response to user

### Secondary Identity Fields

```javascript
metadata: {
  source: "backend/.../textSearchService.js",     // Primary
  chunkIndex: 2,                                  // Which chunk of file
  repository: "anatolyZader/vc-3",               // Which repo
  branch: "main",                                 // Which branch
  commit_sha: "abc123",                          // Which version
  sha: "def456"                                   // File's git sha
}
```

**Combined, these provide**:
- File location: `source`
- Chunk location within file: `chunkIndex`
- Repository context: `repository` + `branch`
- Version tracking: `commit_sha` + `sha`

---

## ğŸ” Verification Points

### At Storage (PostgreSQL)

```sql
-- Check file_path column matches metadata.source
SELECT 
  file_path,
  chunk_index,
  (metadata->>'source') as metadata_source,
  file_path = (metadata->>'source') as paths_match
FROM repo_data
WHERE user_id = 'some-user-id'
LIMIT 10;
```

**Expected**: `paths_match = true` for all rows

### At Storage (Pinecone)

```javascript
// Check metadata.source exists in stored vectors
const queryResponse = await index.namespace(namespace).query({
  vector: queryEmbedding,
  topK: 10,
  includeMetadata: true
});

queryResponse.matches.forEach(match => {
  console.log('Source:', match.metadata.source);  // Should always exist
  console.log('ChunkIndex:', match.metadata.chunkIndex);
});
```

**Expected**: Every match has `metadata.source`

### At Retrieval

```javascript
// Check results contain source information
const results = await vectorSearchOrchestrator.performSearch("some query");

results.forEach(result => {
  console.log('Source:', result.metadata.source);  // Should always exist
  console.log('Content preview:', result.pageContent.substring(0, 100));
});
```

**Expected**: Every result has `metadata.source`

---

## ğŸ›¡ï¸ Protection Mechanisms

### 1. **Fallback Values**

```javascript
const filePath = chunk.metadata?.source || chunk.metadata?.filePath || 'unknown';
```

Ensures identity never completely lost, even if primary field missing.

### 2. **Database Constraints**

```sql
-- Unique constraint ensures no duplicate chunks
ON CONFLICT (user_id, repo_id, file_path, chunk_index) 
DO UPDATE SET ...
```

Prevents identity confusion from duplicates.

### 3. **Metadata Validation**

```javascript
if (!content || content.trim().length === 0) {
  skipped++;
  continue;  // Skip chunks without content
}
```

Prevents storing incomplete chunks that might lose identity.

### 4. **Explicit Field Copying**

```javascript
metadata: {
  ...ubiquitousEnhanced.metadata,  // Copy all fields
  ...chunk.metadata                 // Merge chunk-specific
}
```

Explicit copying ensures no accidental field loss.

---

## ğŸ“ˆ Identity Flow Summary

```
Source File Identity Created
    â†“ (metadata.source = "path/to/file.js")
Document Loaded
    â†“ (source preserved)
Document Processed
    â†“ (source preserved)
Document Split into Chunks
    â†“ (source inherited by each chunk + chunkIndex added)
Chunks Enhanced with Metadata
    â†“ (source still preserved)
    â”œâ”€â†’ Pinecone Storage (source in metadata)
    â””â”€â†’ PostgreSQL Storage (source in column + JSON)
         â†“
Search Query Executed
    â†“
Results Retrieved with Metadata
    â†“ (source returned)
Context Built for LLM
    â†“ (source used for citations)
Response Generated
    â†“ (source shown to user)
User Sees File Path in Answer
```

**Result**: Complete traceability from file to response! ğŸ¯

---

## âœ… Conclusion

File identity is preserved through:

1. **Single Source of Truth**: `metadata.source` field
2. **Inheritance Pattern**: Chunks inherit parent document metadata
3. **Dual Storage**: PostgreSQL stores in both column and JSON
4. **Complete Passthrough**: Every stage preserves metadata
5. **Explicit Extraction**: Critical fields explicitly accessed
6. **No Transformation**: Source path never modified
7. **Return in Results**: Metadata included in search results
8. **User Visibility**: Source paths shown in AI responses

**The identity chain is unbroken from loading to retrieval.** âœ…
